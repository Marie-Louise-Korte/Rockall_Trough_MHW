{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mooring Data from the Rocakall Trough\n",
    "EB1, WB1 & WB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import gsw\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/SAMS_moorings/') \n",
    "# data_path =  Path('./data/')\n",
    "\n",
    "# moor = 'rtwb1'\n",
    "moor = 'rtwb2'\n",
    "# moor = 'rteb1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moor_data(data_path,moor,year):\n",
    "    def __dms2dd(degrees, minutes, direction):\n",
    "        dd = float(degrees) + float(minutes)/60;\n",
    "        if direction == 'W' or direction == 'S':\n",
    "            dd *= -1\n",
    "        return dd;\n",
    "    \n",
    "    def __depth_func(value_chosen,moor):\n",
    "\n",
    "        minimum = float(\"inf\")\n",
    "        if moor == 'rteb1':\n",
    "            setted_list = [50, 75, 100, 250, 500, 750,755,950,1000, 1250, 1500,1600, 1775]\n",
    "        else:\n",
    "            setted_list = [50, 75, 100, 250, 500, 750, 1000, 1250, 1500, 1750]\n",
    "        for val in setted_list:\n",
    "            if abs(val - value_chosen) < minimum:\n",
    "               final_value = float(val)\n",
    "               minimum = abs(val - value_chosen)\n",
    "        return final_value\n",
    "\n",
    "    def __read_header(file,moor):\n",
    "\n",
    "        with open(file) as myfile:\n",
    "            head = [next(myfile) for x in range(10)]\n",
    "            attr_str={}\n",
    "            coord_str={}\n",
    "            for line in head:\n",
    "                info = re.split('[ \\n]+',line)\n",
    "                if info[0]=='Latitude' or info[0]=='Longitude':\n",
    "                    attr_str[info[0]] = __dms2dd(info[2],info[3],info[4])\n",
    "                elif info[0]=='InstrDepth':\n",
    "                    if str(file)[-26:]=='rteb1_04_2017_007.microcat' or str(file)[-26:]=='rteb1_05_2018_006.microcat':\n",
    "                        coord_str['depth'] = ('depth',[float(755)])\n",
    "                    else:\n",
    "                        coord_str['depth'] = ('depth',[__depth_func(float(info[2]),moor)])\n",
    "                else:\n",
    "                    attr_str[info[0]] = info[2]\n",
    "            attr_str['Latitude_units'] = 'degrees_north'\n",
    "            attr_str['Longitude_units'] = 'degrees_east'\n",
    "        return attr_str,coord_str\n",
    "    \n",
    "    def __load_csv_as_xr(file,moor):\n",
    "        attr_str = __read_header(file,moor)\n",
    "        cols = ['yyyy', 'mm', 'dd', 'hh', 'temp', 'cond', 'pres']\n",
    "        df = pd.read_csv(file, sep='\\s+' ,parse_dates={'dates': [0,1,2,3]}, squeeze=True, \n",
    "                         header = None, skiprows = 11, names = cols, engine='python')\n",
    "\n",
    "        for idx,dt in enumerate(df['dates']):\n",
    "            date_str =dt[:4]+dt[5:7]+dt[8:10]\n",
    "            df['dates'][idx]=(pd.to_datetime(date_str,format='%Y%m%d')+datetime.timedelta(hours=np.float(dt[11:])))\n",
    "\n",
    "        ds = xr.Dataset.from_dataframe(df)\n",
    "        attr_str,coord_str = __read_header(file,moor)\n",
    "        ds.coords['time']=ds.dates\n",
    "        ds = ds.swap_dims({'index':'time'}).drop('index').drop_vars('dates')\n",
    "        ds.attrs = attr_str\n",
    "        ds = ds.expand_dims('depth')\n",
    "        ds = ds.assign_coords(coord_str)\n",
    "        ds['sal'] = gsw.SP_from_C(ds.cond, ds.temp, ds.pres)\n",
    "        ds = ds.drop_vars('cond')\n",
    "        return ds\n",
    "\n",
    "    def __get_filelist(data_path,moor,year):\n",
    "        file_list = list(sorted(\n",
    "            (data_path).glob(f\"{moor}_??_{year}*/microcat/{moor}_*.microcat\")\n",
    "            ))\n",
    "        return file_list\n",
    "\n",
    "    files = __get_filelist(data_path,moor,year)\n",
    "    ds = __load_csv_as_xr(files[0],moor)\n",
    "    for file in files[1:]:\n",
    "        ds = xr.concat([ds,__load_csv_as_xr(file,moor)],dim='depth')\n",
    "    \n",
    "    ds.depth.attrs['units']='m'\n",
    "    \n",
    "    ds.temp.attrs['standard_name'] = \"sea_water_temperature\" ;\n",
    "    ds.temp.attrs['long_name'] = \"In Situ Temperature of Sea Water\" ;\n",
    "    ds.temp.attrs['units'] = \"degree_C\" ;\n",
    "    \n",
    "    ds.sal.attrs['standard_name'] = \"sea_water_salinity\" ;\n",
    "    ds.sal.attrs['long_name'] = \"Practical Salinity on the PSS-78 scale\" ;\n",
    "    ds.sal.attrs['units'] = \"unitless\" ;\n",
    "    \n",
    "    ds.pres.attrs['standard_name'] = 'sea_water_pressure'\n",
    "    ds.pres.attrs['long_name'] = 'Pressure of Sea Water'\n",
    "    ds.pres.attrs['units'] = 'dbar'\n",
    "        \n",
    "    ds.attrs['Mooring'] = f'{moor}'\n",
    "    del ds.attrs['SerialNumber']\n",
    "    \n",
    "    \n",
    "    if moor == 'rteb1':\n",
    "        setted_list = [50, 75, 100, 250, 500, 750,755,950,1000, 1250, 1500,1600, 1775]\n",
    "    else:\n",
    "        setted_list = [50, 75, 100, 250, 500, 750, 1000, 1250, 1500, 1750]\n",
    "    for val in setted_list:\n",
    "        if val not in ds.depth:\n",
    "            dummy = ds.isel(depth=1)\n",
    "            dummy['depth'] = val\n",
    "            for var in ds.var(): dummy[var] = dummy[var]*np.nan\n",
    "            ds = xr.concat([ds,dummy],dim='depth')\n",
    "    \n",
    "    return ds.sortby('depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "ds = load_moor_data(data_path,moor,2014)\n",
    "# ds1 = load_moor_data(data_path,moor,2015)\n",
    "for year in np.arange(2015,2019):\n",
    "    display(year)\n",
    "    ds = xr.concat([ds,load_moor_data(data_path,moor,year)],dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1D = ds.resample(time = \"1D\").mean(keep_attrs=True);\n",
    "ds1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1D.to_netcdf(f'data/{moor}_all_merged.nc', \n",
    "        engine='netcdf4',\n",
    "        encoding={'time':{'units':'days since 1900-01-01 00:00:00'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.pres.where(ds.pres>0).plot.line(x='time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_MHW]",
   "language": "python",
   "name": "conda-env-py3_MHW-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
