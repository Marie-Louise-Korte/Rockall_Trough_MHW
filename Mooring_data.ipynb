{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mooring Data from the Rocakall Trough\n",
    "EB1, WB1 & WB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import gsw\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =  Path('data/SAMS_moorings/') # Path('./data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mooring              = rteb1_01_2014    \n",
    "\n",
    "SerialNumber         = 11324      \n",
    "\n",
    "WaterDepth           = 1800      \n",
    "\n",
    "InstrDepth           = 730      \n",
    "\n",
    "Start_Date           = 2014/07/18\n",
    "\n",
    "Start_Time           = 12:30\n",
    "\n",
    "End_Date             = 2015/06/20\n",
    "\n",
    "End_Time             = 06:30\n",
    "\n",
    "Latitude             = 57 05.960 N\n",
    "\n",
    "Longitude            = 009 32.880 W\n",
    "\n",
    "Columns              = YY:MM:DD:HH:T:C:P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moor_data(data_path,moor,year):\n",
    "    def __dms2dd(degrees, minutes, direction):\n",
    "        dd = float(degrees) + float(minutes)/60;\n",
    "        if direction == 'W' or direction == 'S':\n",
    "            dd *= -1\n",
    "        return dd;\n",
    "    \n",
    "    def __depth_func(value_chosen):\n",
    "\n",
    "        minimum = float(\"inf\")\n",
    "        setted_list = [50, 75, 100, 250, 500, 750, 1000, 1250, 1500, 1750]\n",
    "        for val in setted_list:\n",
    "           if abs(val - value_chosen) < minimum:\n",
    "               final_value = val\n",
    "               minimum = abs(val - value_chosen)\n",
    "        return final_value\n",
    "\n",
    "    def __read_header(file):\n",
    "\n",
    "        with open(file) as myfile:\n",
    "            head = [next(myfile) for x in range(10)]\n",
    "            attr_str={}\n",
    "            coord_str={}\n",
    "            for line in head:\n",
    "                info = re.split('[ \\n]+',line)\n",
    "                if info[0]=='Latitude' or info[0]=='Longitude':\n",
    "                    attr_str[info[0]] = __dms2dd(info[2],info[3],info[4])\n",
    "                elif info[0]=='InstrDepth':\n",
    "                    coord_str['depth'] = ('depth',[__depth_func(float(info[2]))])\n",
    "                else:\n",
    "                    attr_str[info[0]] = info[2]\n",
    "            attr_str['Latitude_units'] = 'degrees_north'\n",
    "            attr_str['Longitude_units'] = 'degrees_east'\n",
    "        return attr_str,coord_str\n",
    "    \n",
    "    def __load_csv_as_xr(file):\n",
    "        attr_str = __read_header(file)\n",
    "        cols = ['yyyy', 'mm', 'dd', 'hh', 'temp', 'cond', 'pres']\n",
    "        df = pd.read_csv(file, sep='\\s+' ,parse_dates={'dates': [0,1,2,3]}, squeeze=True, \n",
    "                         header = None, skiprows = 11, names = cols, engine='python')\n",
    "\n",
    "        for idx,dt in enumerate(df['dates']):\n",
    "            date_str =dt[:4]+dt[5:7]+dt[8:10]\n",
    "            df['dates'][idx]=(pd.to_datetime(date_str,format='%Y%m%d')+datetime.timedelta(hours=np.float(dt[11:])))\n",
    "\n",
    "        ds = xr.Dataset.from_dataframe(df)\n",
    "        attr_str,coord_str = __read_header(file)\n",
    "        ds.coords['time']=ds.dates\n",
    "        ds = ds.swap_dims({'index':'time'}).drop('index').drop_vars('dates')\n",
    "        ds.attrs = attr_str\n",
    "        ds = ds.expand_dims('depth')\n",
    "        ds = ds.assign_coords(coord_str)\n",
    "        ds['sal'] = gsw.SP_from_C(ds.cond, ds.temp, ds.pres)\n",
    "        ds = ds.drop_vars('cond')\n",
    "        return ds\n",
    "\n",
    "    def __get_filelist(data_path,moor,year):\n",
    "        file_list = list(sorted(\n",
    "            (data_path).glob(f\"{moor}_??_{year}*/microcat/{moor}_*.microcat\")\n",
    "            ))\n",
    "        return file_list\n",
    "\n",
    "    files = __get_filelist(data_path,moor,year)\n",
    "    ds = __load_csv_as_xr(files[0])\n",
    "    for file in files[1:]:\n",
    "        ds = xr.concat([ds,__load_csv_as_xr(file)],dim='depth')\n",
    "    \n",
    "    ds.depth.attrs['units']='m'\n",
    "    \n",
    "    ds.temp.attrs['standard_name'] = \"sea_water_temperature\" ;\n",
    "    ds.temp.attrs['long_name'] = \"In Situ Temperature of Sea Water\" ;\n",
    "    ds.temp.attrs['units'] = \"degree_C\" ;\n",
    "    \n",
    "    ds.sal.attrs['standard_name'] = \"sea_water_salinity\" ;\n",
    "    ds.sal.attrs['long_name'] = \"Practical Salinity on the PSS-78 scale\" ;\n",
    "    ds.sal.attrs['units'] = \"unitless\" ;\n",
    "    \n",
    "    ds.pres.attrs['standard_name'] = 'sea_water_pressure'\n",
    "    ds.pres.attrs['long_name'] = 'Pressure of Sea Water'\n",
    "    ds.pres.attrs['units'] = 'dbar'\n",
    "    \n",
    "    ds.time.attrs['units'] = 'days since 1950-01-01 00:00:00'\n",
    "        \n",
    "    ds.attrs['Mooring'] = f'{moor}'\n",
    "    del ds.attrs['SerialNumber']\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex or align along dimension 'depth' because the index has duplicate values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py3_MHW/lib/python3.9/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;34m\"objects, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n\u001b[0;32m--> 239\u001b[0;31m     return f(\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine_attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py3_MHW/lib/python3.9/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     datasets = list(\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py3_MHW/lib/python3.9/site-packages/xarray/core/alignment.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             new_obj = obj.reindex(\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py3_MHW/lib/python3.9/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, indexers, method, tolerance, copy, fill_value, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m         \"\"\"\n\u001b[0;32m-> 2785\u001b[0;31m         return self._reindex(\n\u001b[0m\u001b[1;32m   2786\u001b[0m             \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py3_MHW/lib/python3.9/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_reindex\u001b[0;34m(self, indexers, method, tolerance, copy, fill_value, sparse, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2812\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid reindex dimensions: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbad_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2814\u001b[0;31m         variables, indexes = alignment.reindex_variables(\n\u001b[0m\u001b[1;32m   2815\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py3_MHW/lib/python3.9/site-packages/xarray/core/alignment.py\u001b[0m in \u001b[0;36mreindex_variables\u001b[0;34m(variables, sizes, indexes, indexers, method, tolerance, copy, fill_value, sparse)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    569\u001b[0m                     \u001b[0;34m\"cannot reindex or align along dimension %r because the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0;34m\"index has duplicate values\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex or align along dimension 'depth' because the index has duplicate values"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "moor = 'rtwb1'\n",
    "ds = load_moor_data(data_path,moor,2014)\n",
    "   \n",
    "for year in np.arange(2015,2018):\n",
    "    ds = xr.concat([ds,load_moor_data(data_path,moor,year)],dim='time')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.set_options(keep_attrs=True):\n",
    "    ds1D = ds.resample(time = \"1D\").mean()\n",
    "\n",
    "#ds1D = ds.resample(time = \"1D\").mean(keep_attrs=True);\n",
    "#ds1D.time.attrs = ds.time.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1D.to_netcdf(f'data/{moor}_all_merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.pres.plot.line(x='time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_MHW]",
   "language": "python",
   "name": "conda-env-py3_MHW-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
